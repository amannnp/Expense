{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb753133-4822-4044-97a2-e0c1b1a6baa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4348 - loss: 3.2615 - val_accuracy: 1.0000 - val_loss: 1.0365\n",
      "Epoch 2/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.9949 - val_accuracy: 1.0000 - val_loss: 0.7016\n",
      "Epoch 3/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.7544 - val_accuracy: 1.0000 - val_loss: 0.5926\n",
      "Epoch 4/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.6472 - val_accuracy: 1.0000 - val_loss: 0.5249\n",
      "Epoch 5/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.5759 - val_accuracy: 1.0000 - val_loss: 0.4739\n",
      "Epoch 6/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.5251 - val_accuracy: 1.0000 - val_loss: 0.4385\n",
      "Epoch 7/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.4833 - val_accuracy: 1.0000 - val_loss: 0.4052\n",
      "Epoch 8/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.4477 - val_accuracy: 1.0000 - val_loss: 0.3818\n",
      "Epoch 9/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.4238 - val_accuracy: 1.0000 - val_loss: 0.3588\n",
      "Epoch 10/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.3972 - val_accuracy: 1.0000 - val_loss: 0.3416\n",
      "Epoch 11/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.3790 - val_accuracy: 1.0000 - val_loss: 0.3240\n",
      "Epoch 12/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.3596 - val_accuracy: 1.0000 - val_loss: 0.3097\n",
      "Epoch 13/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.3458 - val_accuracy: 1.0000 - val_loss: 0.2979\n",
      "Epoch 14/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.3339 - val_accuracy: 1.0000 - val_loss: 0.2833\n",
      "Epoch 15/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.3215 - val_accuracy: 1.0000 - val_loss: 0.2757\n",
      "Epoch 16/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.3099 - val_accuracy: 1.0000 - val_loss: 0.2640\n",
      "Epoch 17/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2950 - val_accuracy: 1.0000 - val_loss: 0.2563\n",
      "Epoch 18/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.2867 - val_accuracy: 1.0000 - val_loss: 0.2467\n",
      "Epoch 19/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2764 - val_accuracy: 1.0000 - val_loss: 0.2390\n",
      "Epoch 20/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2696 - val_accuracy: 1.0000 - val_loss: 0.2312\n",
      "Epoch 21/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2589 - val_accuracy: 1.0000 - val_loss: 0.2240\n",
      "Epoch 22/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2507 - val_accuracy: 1.0000 - val_loss: 0.2185\n",
      "Epoch 23/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2461 - val_accuracy: 1.0000 - val_loss: 0.2103\n",
      "Epoch 24/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 0.2372 - val_accuracy: 1.0000 - val_loss: 0.2056\n",
      "Epoch 25/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.2319 - val_accuracy: 1.0000 - val_loss: 0.2000\n",
      "Epoch 26/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.2264 - val_accuracy: 1.0000 - val_loss: 0.1952\n",
      "Epoch 27/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.2212 - val_accuracy: 1.0000 - val_loss: 0.1893\n",
      "Epoch 28/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2141 - val_accuracy: 1.0000 - val_loss: 0.1874\n",
      "Epoch 29/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.2087 - val_accuracy: 1.0000 - val_loss: 0.1803\n",
      "Epoch 30/30\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2023 - val_accuracy: 1.0000 - val_loss: 0.1741\n",
      "Evaluating on test set...\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Dining       1.00      1.00      1.00       192\n",
      "    Education       1.00      1.00      1.00       183\n",
      "Entertainment       1.00      1.00      1.00       174\n",
      "         Fuel       1.00      1.00      1.00       164\n",
      "    Groceries       1.00      1.00      1.00       180\n",
      "   Healthcare       1.00      1.00      1.00       188\n",
      "       Others       1.00      1.00      1.00       181\n",
      "     Shopping       1.00      1.00      1.00       196\n",
      "       Travel       1.00      1.00      1.00       187\n",
      "    Utilities       1.00      1.00      1.00       155\n",
      "\n",
      "     accuracy                           1.00      1800\n",
      "    macro avg       1.00      1.00      1.00      1800\n",
      " weighted avg       1.00      1.00      1.00      1800\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[192   0   0   0   0   0   0   0   0   0]\n",
      " [  0 183   0   0   0   0   0   0   0   0]\n",
      " [  0   0 174   0   0   0   0   0   0   0]\n",
      " [  0   0   0 164   0   0   0   0   0   0]\n",
      " [  0   0   0   0 180   0   0   0   0   0]\n",
      " [  0   0   0   0   0 188   0   0   0   0]\n",
      " [  0   0   0   0   0   0 181   0   0   0]\n",
      " [  0   0   0   0   0   0   0 196   0   0]\n",
      " [  0   0   0   0   0   0   0   0 187   0]\n",
      " [  0   0   0   0   0   0   0   0   0 155]]\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\KIIT\\AppData\\Local\\Temp\\tmpjbqf29hw\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\KIIT\\AppData\\Local\\Temp\\tmpjbqf29hw\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\KIIT\\AppData\\Local\\Temp\\tmpjbqf29hw'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, 96), dtype=tf.float32, name='text_input'), TensorSpec(shape=(None, 1), dtype=tf.float32, name='amount_input')]\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1452352498448: TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)\n",
      "  1452352497680: TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)\n",
      "  1452352496912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1452352498256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1452352499792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1452352496720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1452352500176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1452352501328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "All files saved:\n",
      "- expense_model.tflite\n",
      "- amount_normalizer.npy\n",
      "- tfidf_vocab.json\n",
      "- label_classes.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Normalization, Concatenate, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import json\n",
    "import os\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "CSV_PATH = 'expense_dataset.csv'\n",
    "TFLITE_MODEL_PATH = 'expense_model.tflite'\n",
    "TFIDF_VOCAB_PATH = 'tfidf_vocab.json'\n",
    "SCALER_PATH = 'amount_normalizer.npy'\n",
    "LABEL_ENCODER_PATH = 'label_classes.json'\n",
    "# ============================\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df['text'] = df['merchant'].astype(str) + ' ' + df['description'].astype(str)\n",
    "texts = df['text'].values\n",
    "amounts = df['amount'].values\n",
    "labels = df['category'].values\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(labels)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# TF-IDF for text\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_text = tfidf.fit_transform(texts).toarray()\n",
    "\n",
    "# Save vocab\n",
    "with open(TFIDF_VOCAB_PATH, 'w') as f:\n",
    "    json.dump({k: int(v) for k, v in tfidf.vocabulary_.items()}, f)\n",
    "\n",
    "# Split data\n",
    "X_text_train, X_text_test, X_amount_train, X_amount_test, y_train, y_test = train_test_split(\n",
    "    X_text, amounts, y_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Normalize amount\n",
    "amount_normalizer = Normalization()\n",
    "amount_normalizer.adapt(X_amount_train.reshape(-1, 1))\n",
    "\n",
    "# Save scaler stats\n",
    "np.save(SCALER_PATH, {\n",
    "    'mean': amount_normalizer.mean.numpy().tolist(),\n",
    "    'var': amount_normalizer.variance.numpy().tolist()\n",
    "})\n",
    "\n",
    "# Save label classes\n",
    "with open(LABEL_ENCODER_PATH, 'w') as f:\n",
    "    json.dump(label_encoder.classes_.tolist(), f)\n",
    "\n",
    "# Build model\n",
    "text_input = Input(shape=(X_text_train.shape[1],), name='text_input')\n",
    "amount_input = Input(shape=(1,), dtype=tf.float32, name='amount_input')\n",
    "x_amount = amount_normalizer(amount_input)\n",
    "x = Concatenate()([text_input, x_amount])\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[text_input, amount_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train with validation and early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    {'text_input': X_text_train, 'amount_input': X_amount_train}, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "print(\"Evaluating on test set...\")\n",
    "y_pred_probs = model.predict({'text_input': X_text_test, 'amount_input': X_amount_test})\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Convert to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "with open(TFLITE_MODEL_PATH, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"All files saved:\")\n",
    "print(\"- expense_model.tflite\")\n",
    "print(\"- amount_normalizer.npy\")\n",
    "print(\"- tfidf_vocab.json\")\n",
    "print(\"- label_classes.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe93c8-41b7-494d-aea0-5ecbff1595f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
